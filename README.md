# Matrix Low-Rank Trust Region Policy Optimization

by
Sergio Rozada,
and Antonio G. Marques

This code belongs to a paper that has been submitted for publication in *CAMSAP 2023*.

> The associated paper presents low-rank matrix models for Trust-Region Policy Optimization (TRPO) methods. They are easy to tune, and parametrize. They outperform neural networks in terms of size, and returns.

<p align="center">
    <img src="figures/fig1.png" alt="drawing" width="400"/>
</p>


*Median return per episode in three standard RL problems:
(a) the pendulum, (b) the acrobot, and (d) the mountain car problem.*


## Abstract

> Most methods in reinforcement learning use a Policy Gradient (PG) approach to learn a parametric stochastic policy that maps states to actions. The standard approach is to implement such a mapping via a neural network (NN) whose parameters are optimized using stochastic gradient descent. However, PG methods are prone to large policy updates that can render learning inefficient. Trust region algorithms, like Trust Region Policy Optimization (TRPO), constrain the policy update step, ensuring monotonic improvements. This paper introduces low-rank matrix-based models as an efficient alternative for estimating the parameters of TRPO algorithms. By gathering the stochastic policy's parameters into a matrix and applying matrix-completion techniques, we promote and enforce low rank. Our numerical studies demonstrate that low-rank matrix-based policy models effectively reduce both computational and sample complexities compared to NN models, while maintaining comparable aggregated rewards.


## Software implementation

All source code used to generate the results and figures in the paper are in the `src` folder. The calculations and figure generation are all done by running:
* `main_pendulum.py`
* `main_acrobot.py`
* `main_mountaincar.py`
* `plot.py`

Results generated by the code are saved in `results`, and figures are saved in `figures`.


## Getting the code

You can download a copy of all the files in this repository by cloning the
[git](https://github.com/sergiorozada12/matrix-low-rank-trpo) repository:

    git clone https://github.com/sergiorozada12/matrix-low-rank-trpo.git

or [download a zip archive](https://github.com/sergiorozada12/matrix-low-rank-trpo/archive/refs/heads/main.zip).


## Dependencies

You'll need a working Python environment to run the code.
The recommended way to set up your environment is through [virtual environments](https://docs.python.org/3/library/venv.html). The required dependencies are specified in the file `requirements.txt`.
